{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, numpy as np, pandas as pd\n",
    "\n",
    "def load_config(path='default_config.yaml', **ov):\n",
    "    with open(path) as f: cfg = yaml.safe_load(f)\n",
    "    cfg.update(ov)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config()  # or: load_config(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 folds, test set: 504 days\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Data Loading & Cross-Validation Splits\n",
    "# =============================================================================\n",
    "# Expanding window validation for financial time series\n",
    "# Avoids look-ahead bias and tests across multiple market regimes\n",
    "# Reference: de Prado (2018) \"Advances in Financial Machine Learning\", Ch. 7\n",
    "\n",
    "def create_folds(data, test_years=2, init_train_years=10, val_years=1, step_years=1):\n",
    "    \"\"\"\n",
    "    Expanding window cross-validation for time series.\n",
    "    \n",
    "    Returns:\n",
    "        folds: list of (train_df, val_df) tuples\n",
    "        test: held-out test set (final test_years of data)\n",
    "    \"\"\"\n",
    "    days_per_year = 252  # trading days\n",
    "    \n",
    "    # Hold out final test set\n",
    "    test_size = test_years * days_per_year\n",
    "    test = data.iloc[-test_size:]\n",
    "    remaining = data.iloc[:-test_size]\n",
    "    \n",
    "    # Create expanding folds\n",
    "    folds = []\n",
    "    train_end = init_train_years * days_per_year\n",
    "    val_size = val_years * days_per_year\n",
    "    step = step_years * days_per_year\n",
    "    \n",
    "    while train_end + val_size <= len(remaining):\n",
    "        train = remaining.iloc[:train_end]\n",
    "        val = remaining.iloc[train_end:train_end + val_size]\n",
    "        folds.append((train, val))\n",
    "        train_end += step\n",
    "    \n",
    "    return folds, test\n",
    "\n",
    "data = pd.read_csv('data.csv', index_col=0, parse_dates=True)\n",
    "folds, test = create_folds(data)\n",
    "print(f\"Created {len(folds)} folds, test set: {len(test)} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Weights Sharpe: 1.645\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Equal Weights Baseline\n",
    "# =============================================================================\n",
    "# 1/N portfolio - surprisingly hard to beat (DeMiguel et al., 2009)\n",
    "# Reference: DeMiguel, Garlappi & Uppal (2009) \"Optimal Versus Naive \n",
    "#            Diversification\", Review of Financial Studies\n",
    "\n",
    "w = np.ones(test.shape[1]) / test.shape[1]\n",
    "r = (test * w).sum(axis=1)\n",
    "ew_sharpe = r.mean() / r.std() * np.sqrt(252)\n",
    "print(f\"Equal Weights Sharpe: {ew_sharpe:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: DDPG / DDES-DDPG Runner\n",
    "# =============================================================================\n",
    "# DDPG: Lillicrap et al. (2015) \"Continuous control with deep reinforcement learning\"\n",
    "# DDES: Hong et al. (2018) \"Diversity-Driven Exploration Strategy for Deep RL\"\n",
    "#\n",
    "# Key difference:\n",
    "#   DDPG  - exploration via Gaussian noise on actions\n",
    "#   DDES  - exploration via diversity term in actor loss: -Q(s,a) + Î± * D(a, a_prior)\n",
    "\n",
    "from models.ddpg import DDPG\n",
    "from models.networks import NeuralNetwork\n",
    "\n",
    "def run_ddpg(train, val, test, cfg, use_ddes=False):\n",
    "    \"\"\"Train and evaluate DDPG or DDES-DDPG.\"\"\"\n",
    "    agent = DDPG(\n",
    "        lookback_window=cfg['lookback_window'],\n",
    "        predictor=NeuralNetwork,\n",
    "        batch_size=cfg['batch_size'],\n",
    "        hidden_sizes=cfg['hidden_sizes'],\n",
    "        seed=cfg['seeds'][0],\n",
    "    )\n",
    "    agent.train(\n",
    "        train, val,\n",
    "        actor_lr=cfg['actor_lr'],\n",
    "        critic_lr=cfg['critic_lr'],\n",
    "        gamma=cfg['gamma'],\n",
    "        tau=cfg['tau'],\n",
    "        soft_update=cfg['soft_update'],\n",
    "        num_epochs=cfg['num_epochs'],\n",
    "        patience=cfg['patience'],\n",
    "        noise=cfg['noise'],\n",
    "        use_ddes=use_ddes,\n",
    "        ddes_alpha=cfg['ddes_alpha'],\n",
    "    )\n",
    "    _, (_, sharpe) = agent.evaluate(test)\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Train: 2520 days, Val: 252 days\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DDPG.train() got an unexpected keyword argument 'noise'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(folds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m days, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m days\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mDDPG\u001b[39m\u001b[33m'\u001b[39m].append(\u001b[43mrun_ddpg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ddes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m     11\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mDDES\u001b[39m\u001b[33m'\u001b[39m].append(run_ddpg(train, val, test, cfg, use_ddes=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mrun_ddpg\u001b[39m\u001b[34m(train, val, test, cfg, use_ddes)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Train and evaluate DDPG or DDES-DDPG.\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m agent = DDPG(\n\u001b[32m     17\u001b[39m     lookback_window=cfg[\u001b[33m'\u001b[39m\u001b[33mlookback_window\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     18\u001b[39m     predictor=NeuralNetwork,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     seed=cfg[\u001b[33m'\u001b[39m\u001b[33mseeds\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mactor_lr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcritic_lr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgamma\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtau\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43msoft_update\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msoft_update\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpatience\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnoise\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_ddes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_ddes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mddes_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mddes_alpha\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m _, (_, sharpe) = agent.evaluate(test)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sharpe\n",
      "\u001b[31mTypeError\u001b[39m: DDPG.train() got an unexpected keyword argument 'noise'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Run Experiments Across Folds\n",
    "# =============================================================================\n",
    "results = {'EW': ew_sharpe, 'DDPG': [], 'DDES': []}\n",
    "\n",
    "for i, (train, val) in enumerate(folds):\n",
    "    print(f\"\\n--- Fold {i+1}/{len(folds)} ---\")\n",
    "    print(f\"Train: {len(train)} days, Val: {len(val)} days\")\n",
    "    \n",
    "    results['DDPG'].append(run_ddpg(train, val, test, cfg, use_ddes=False))\n",
    "    results['DDES'].append(run_ddpg(train, val, test, cfg, use_ddes=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
