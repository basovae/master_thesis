{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edb2d6c",
   "metadata": {},
   "source": [
    "# # Portfolio Optimization Experiments\n",
    "# \n",
    "# This notebook demonstrates how to use the configuration system and validation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d71e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (6.0.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]━━━━\u001b[0m \u001b[32m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.5 pandas-2.3.3 pytz-2025.2 tzdata-2025.3\n",
      "Collecting yfinance\n",
      "  Using cached yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in ./.venv/lib/python3.13/site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./.venv/lib/python3.13/site-packages (from yfinance) (2.3.5)\n",
      "Collecting requests>=2.31 (from yfinance)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Using cached multitasking-0.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in ./.venv/lib/python3.13/site-packages (from yfinance) (4.5.1)\n",
      "Requirement already satisfied: pytz>=2022.5 in ./.venv/lib/python3.13/site-packages (from yfinance) (2025.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Using cached frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Using cached peewee-3.18.3.tar.gz (3.0 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Using cached curl_cffi-0.14.0-cp39-abi3-macosx_14_0_arm64.whl.metadata (15 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Using cached protobuf-6.33.2-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting cffi>=1.12.0 (from curl_cffi>=0.7->yfinance)\n",
      "  Using cached cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting certifi>=2024.2.2 (from curl_cffi>=0.7->yfinance)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12.0->curl_cffi>=0.7->yfinance)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31->yfinance)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.31->yfinance)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->yfinance)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Using cached yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Using cached curl_cffi-0.14.0-cp39-abi3-macosx_14_0_arm64.whl (3.1 MB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl (181 kB)\n",
      "Using cached frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Using cached protobuf-6.33.2-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.18.3-cp313-cp313-macosx_15_0_arm64.whl size=283983 sha256=3ac5736e5aea46a7f1921c5460d877a5a979af6a75674d78e0cdadbe8d85db9d\n",
      "  Stored in directory: /Users/ekaterinabasova/Library/Caches/pip/wheels/8c/a9/a4/df972cd49f865ffde174d9c5b26f14f08f8a363ed31e10ff91\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, urllib3, typing-extensions, soupsieve, pycparser, protobuf, idna, frozendict, charset_normalizer, certifi, requests, cffi, beautifulsoup4, curl_cffi, yfinance\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [yfinance]\u001b[0m \u001b[32m15/17\u001b[0m [curl_cffi]rset_normalizer]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.14.3 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 curl_cffi-0.14.0 frozendict-2.4.7 idna-3.11 multitasking-0.0.12 peewee-3.18.3 protobuf-6.33.2 pycparser-2.23 requests-2.32.5 soupsieve-2.8.1 typing-extensions-4.15.0 urllib3-2.6.2 websockets-15.0.1 yfinance-0.2.66\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.3.5)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: mpmath, sympy, setuptools, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [torch]8;5;237m━━━━\u001b[0m \u001b[32m8/9\u001b[0m [torch]ools]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.20.1 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 setuptools-80.9.0 sympy-1.14.0 torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml\n",
    "!pip install pandas\n",
    "!pip install yfinance\n",
    "!pip install numpy\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87364c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('config')\n",
    "\n",
    "from config_manager import (\n",
    "    Config, \n",
    "    quick_test_config, \n",
    "    full_experiment_config,\n",
    "    DDPG_SEARCH_SPACE,\n",
    "    DIV_DDPG_SEARCH_SPACE,\n",
    "    PGA_SEARCH_SPACE\n",
    ")\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86db866",
   "metadata": {},
   "source": [
    "# ## 1. Configuration System\n",
    "# \n",
    "# Load defaults and override as needed. All defaults are from original papers.\n",
    "\n",
    "# %%\n",
    "# Option A: Load defaults, no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670031dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default DDPG learning rate: 0.0001\n",
      "Default validation strategy: expanding_window\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "print(f\"Default DDPG learning rate: {cfg.ddpg.actor_lr}\")\n",
    "print(f\"Default validation strategy: {cfg.validation.strategy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554985b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "    ddpg={\n",
    "        'actor_lr': 0.0005,  # changed from 0.0001\n",
    "        'total_timesteps': 100000  # reduced for faster testing\n",
    "    },\n",
    "    validation={\n",
    "        'strategy': 'holdout'  # simpler validation\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.save('experiments/run_001/config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25fc27",
   "metadata": {},
   "source": [
    "# ## 2. Validation Strategies Explained\n",
    "#\n",
    "# ### Expanding Window (Recommended for thesis)\n",
    "# \n",
    "# ```\n",
    "# Year:  05  06  07  08  09  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24\n",
    "#        |----------TRAIN----------|--VAL--|                              |--TEST--|\n",
    "#        |-------------TRAIN---------------|--VAL--|                      |--TEST--|\n",
    "#        |------------------TRAIN------------------|--VAL--|              |--TEST--|\n",
    "#        ...\n",
    "# ```\n",
    "# \n",
    "# - Training window grows each fold\n",
    "# - Validation window slides forward  \n",
    "# - Test set is held out entirely until final evaluation\n",
    "# - Gives multiple performance estimates across market regimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a7e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_expanding_window_splits(\n",
    "    data: pd.DataFrame,\n",
    "    initial_train_years: int = 10,\n",
    "    val_window_years: int = 1,\n",
    "    step_years: int = 1,\n",
    "    final_test_years: int = 2,\n",
    "    purge_gap_days: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Create expanding window splits for time series cross-validation.\n",
    "    \n",
    "    Returns list of (train_idx, val_idx) tuples plus final test_idx.\n",
    "    \"\"\"\n",
    "    trading_days_per_year = 252\n",
    "    \n",
    "    # Calculate indices\n",
    "    n_total = len(data)\n",
    "    test_size = final_test_years * trading_days_per_year\n",
    "    test_start = n_total - test_size\n",
    "    \n",
    "    initial_train_size = initial_train_years * trading_days_per_year\n",
    "    val_size = val_window_years * trading_days_per_year\n",
    "    step_size = step_years * trading_days_per_year\n",
    "    \n",
    "    splits = []\n",
    "    train_end = initial_train_size\n",
    "    \n",
    "    while train_end + purge_gap_days + val_size <= test_start:\n",
    "        train_idx = np.arange(0, train_end)\n",
    "        val_start = train_end + purge_gap_days\n",
    "        val_end = val_start + val_size\n",
    "        val_idx = np.arange(val_start, min(val_end, test_start))\n",
    "        \n",
    "        if len(val_idx) > 0:\n",
    "            splits.append((train_idx, val_idx))\n",
    "        \n",
    "        train_end += step_size\n",
    "    \n",
    "    test_idx = np.arange(test_start, n_total)\n",
    "    \n",
    "    return splits, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4246b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation folds: 7\n",
      "Test set size: 504 days\n",
      "Fold 1: train=2520 days, val=252 days\n",
      "Fold 2: train=2772 days, val=252 days\n",
      "Fold 3: train=3024 days, val=252 days\n"
     ]
    }
   ],
   "source": [
    "dates = pd.date_range('2005-01-01', '2024-12-31', freq='B')  # business days\n",
    "dummy_data = pd.DataFrame(index=dates[:5000])  # ~20 years\n",
    "\n",
    "splits, test_idx = create_expanding_window_splits(\n",
    "    dummy_data,\n",
    "    initial_train_years=10,\n",
    "    val_window_years=1,\n",
    "    final_test_years=2\n",
    ")\n",
    "\n",
    "print(f\"Number of validation folds: {len(splits)}\")\n",
    "print(f\"Test set size: {len(test_idx)} days\")\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(splits[:3]):\n",
    "    print(f\"Fold {i+1}: train={len(train_idx)} days, val={len(val_idx)} days\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f851e92",
   "metadata": {},
   "source": [
    "## 3. Experiment Runner Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54493cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentRunner:\n",
    "    \"\"\"\n",
    "    Runs experiments with proper validation and logging.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.cfg = config\n",
    "        self.results = {}\n",
    "        \n",
    "    def run_method(self, method: str, train_data, val_data, seed: int):\n",
    "        \"\"\"\n",
    "        Train and evaluate a single method on given data split.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        method : str\n",
    "            One of 'equal_weights', 'ddpg', 'div_ddpg', 'pga_map_elites'\n",
    "        train_data : pd.DataFrame\n",
    "            Training data (returns)\n",
    "        val_data : pd.DataFrame\n",
    "            Validation data (returns)\n",
    "        seed : int\n",
    "            Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        # Placeholder - actual implementations would go here\n",
    "        if method == 'equal_weights':\n",
    "            # No training needed\n",
    "            return self._evaluate_equal_weights(val_data)\n",
    "        \n",
    "        elif method == 'ddpg':\n",
    "            cfg = self.cfg.ddpg\n",
    "            # agent = DDPGAgent(\n",
    "            #     state_dim=train_data.shape[1] * cfg.lookback_window,\n",
    "            #     action_dim=train_data.shape[1],\n",
    "            #     actor_lr=cfg.actor_lr,\n",
    "            #     critic_lr=cfg.critic_lr,\n",
    "            #     ...\n",
    "            # )\n",
    "            # agent.train(train_data, cfg.total_timesteps)\n",
    "            # return self._evaluate_agent(agent, val_data)\n",
    "            pass\n",
    "        \n",
    "        elif method == 'div_ddpg':\n",
    "            cfg = self.cfg.div_ddpg\n",
    "            # Similar to DDPG but with diversity loss\n",
    "            pass\n",
    "        \n",
    "        elif method == 'pga_map_elites':\n",
    "            cfg = self.cfg.pga_map_elites\n",
    "            # Returns archive of policies, need to select representative\n",
    "            pass\n",
    "    \n",
    "    def run_full_comparison(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Run all methods across all validation folds and seeds.\n",
    "        \"\"\"\n",
    "        methods = ['equal_weights', 'ddpg', 'div_ddpg', 'pga_map_elites']\n",
    "        seeds = self.cfg.validation.random_seeds\n",
    "        \n",
    "        # Create validation splits\n",
    "        splits, test_idx = create_expanding_window_splits(\n",
    "            data,\n",
    "            initial_train_years=self.cfg.validation.temporal.initial_train_years,\n",
    "            val_window_years=self.cfg.validation.temporal.val_window_years,\n",
    "            final_test_years=self.cfg.validation.temporal.final_test_years,\n",
    "            purge_gap_days=self.cfg.validation.temporal.purge_gap_days\n",
    "        )\n",
    "        \n",
    "        results = {method: [] for method in methods}\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(splits):\n",
    "            train_data = data.iloc[train_idx]\n",
    "            val_data = data.iloc[val_idx]\n",
    "            \n",
    "            for method in methods:\n",
    "                for seed in seeds:\n",
    "                    print(f\"Fold {fold_idx+1}, {method}, seed {seed}\")\n",
    "                    \n",
    "                    # Run experiment\n",
    "                    fold_results = self.run_method(\n",
    "                        method, train_data, val_data, seed\n",
    "                    )\n",
    "                    \n",
    "                    fold_results['fold'] = fold_idx\n",
    "                    fold_results['seed'] = seed\n",
    "                    results[method].append(fold_results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_equal_weights(self, data):\n",
    "        \"\"\"Evaluate 1/N portfolio.\"\"\"\n",
    "        n_assets = data.shape[1]\n",
    "        weights = np.ones(n_assets) / n_assets\n",
    "        returns = (data * weights).sum(axis=1)\n",
    "        \n",
    "        return {\n",
    "            'cumulative_return': (1 + returns).prod() - 1,\n",
    "            'sharpe_ratio': returns.mean() / returns.std() * np.sqrt(252),\n",
    "            'max_drawdown': self._max_drawdown(returns),\n",
    "        }\n",
    "    \n",
    "    def _max_drawdown(self, returns):\n",
    "        \"\"\"Calculate maximum drawdown.\"\"\"\n",
    "        cum_returns = (1 + returns).cumprod()\n",
    "        rolling_max = cum_returns.expanding().max()\n",
    "        drawdowns = cum_returns / rolling_max - 1\n",
    "        return drawdowns.min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639ab93",
   "metadata": {},
   "source": [
    "## 4. Running Experiments from Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test run\n",
    "cfg = quick_test_config()\n",
    "\n",
    "# Override anything you want to test\n",
    "#cfg.set('ddpg.actor_lr', 0.0003)\n",
    "#cfg.set('validation.n_seeds', 2)\n",
    "\n",
    "print(\"Running with config:\")\n",
    "print(f\"  DDPG lr: {cfg.ddpg.actor_lr}\")\n",
    "print(f\"  Seeds: {cfg.validation.n_seeds}\")\n",
    "print(f\"  Timesteps: {cfg.ddpg.total_timesteps}\")\n",
    "\n",
    "# runner = ExperimentRunner(cfg)\n",
    "# results = runner.run_full_comparison(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e7e7e",
   "metadata": {},
   "source": [
    "# ## 5. Hyperparameter Search with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a48dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optuna_study(method: str, cfg: Config):\n",
    "    \"\"\"\n",
    "    Create Optuna study for hyperparameter optimization.\n",
    "    \"\"\"\n",
    "    import optuna\n",
    "    \n",
    "    search_space = {\n",
    "        'ddpg': DDPG_SEARCH_SPACE,\n",
    "        'div_ddpg': DIV_DDPG_SEARCH_SPACE,\n",
    "        'pga_map_elites': PGA_SEARCH_SPACE\n",
    "    }[method]\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Sample hyperparameters\n",
    "        overrides = {}\n",
    "        for param, spec in search_space.items():\n",
    "            if spec['type'] == 'loguniform':\n",
    "                value = trial.suggest_float(param, spec['low'], spec['high'], log=True)\n",
    "            elif spec['type'] == 'uniform':\n",
    "                value = trial.suggest_float(param, spec['low'], spec['high'])\n",
    "            elif spec['type'] == 'categorical':\n",
    "                value = trial.suggest_categorical(param, spec['choices'])\n",
    "            \n",
    "            # Handle nested params like 'diversity.alpha_initial'\n",
    "            keys = param.split('.')\n",
    "            d = overrides\n",
    "            for k in keys[:-1]:\n",
    "                d = d.setdefault(k, {})\n",
    "            d[keys[-1]] = value\n",
    "        \n",
    "        # Create config with sampled hyperparameters\n",
    "        trial_cfg = Config(**{method: overrides})\n",
    "        \n",
    "        # Run experiment and return validation metric\n",
    "        # runner = ExperimentRunner(trial_cfg)\n",
    "        # results = runner.run_method(method, train_data, val_data, seed=42)\n",
    "        # return results['sharpe_ratio']\n",
    "        \n",
    "        return np.random.random()  # placeholder\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    return study, objective\n",
    "\n",
    "# Usage:\n",
    "# study, objective = create_optuna_study('ddpg', cfg)\n",
    "# study.optimize(objective, n_trials=50)\n",
    "# best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96e30a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
