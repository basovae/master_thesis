# =============================================================================
# config.yaml - Unified config for DDPG and PGA-MAP-Elites
# =============================================================================

# --- Data ---
lookback_window: 20
train_ratio: 0.7
val_ratio: 0.15

# --- Shared Architecture ---
hidden_sizes: [128, 128] # DDPG + PGA actor/critic

# --- Shared RL ---
gamma: 0.99
tau: 0.005
actor_lr: 0.001
critic_lr: 0.0003 # 3e-4

# --- Experiment ---
seeds: [42, 123, 456]

# =============================================================================
# DDPG-specific
# =============================================================================
ddpg:
  batch_size: 1
  num_epochs: 100
  patience: 10
  noise: 0.2

  # DDES (toggle with use_ddes)
  use_ddes: false
  ddes_alpha: 1.0
  ddes_scaling_method: fixed
  ddes_n_prior_samples: 16

# =============================================================================
# PGA-MAP-Elites-specific
# =============================================================================
pga:
  # QD parameters
  n_niches: 256
  max_evals: 20000
  random_init: 500
  batch_size: 100 # actors per iteration

  # Behavior descriptor bounds [volatility, diversification]
  bd_min: [0.0, 0.0]
  bd_max: [0.3, 1.0]

  # Variation operators
  proportion_evo: 0.5 # 50% GA, 50% PG
  iso_sigma: 0.005 # GA: isotropic noise
  line_sigma: 0.05 # GA: directional noise
  nr_of_steps_act: 10 # PG: gradient steps

  # Critic training (TD3)
  nr_of_steps_crit: 300
  train_batch_size: 256
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
